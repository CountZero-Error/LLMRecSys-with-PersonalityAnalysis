{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f12db5f-f8db-4779-a2bb-858fe22202e0",
   "metadata": {},
   "source": [
    "# LLM for Recommendation System - RAG\n",
    "\n",
    "## TABLE OF CONTENT\n",
    "### $~~~$ - 1. Recommendation System\n",
    "### $~~~$ - 2. Result Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838102f-2bd4-4f3f-bc10-2115dfbe6a30",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "id": "b50b3d38-ee00-49e9-a6de-ee2a2f3a5ca2",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "# Check Python vision\n",
    "!python -V\n",
    "# Check CUDA vision\n",
    "!nvcc --version"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3500fbf-bbbb-4e40-8f65-4727a0c49dee",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "from time import time \n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11be73e3-1784-4091-9074-d17e37915c35",
   "metadata": {},
   "source": [
    "# Check for GPU Availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available else \"cpu\")\n",
    "#device = 'cpu' # Set to cpu when debugging\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "access_token = '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'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = access_token\n",
    "\n",
    "base_dir = \"../..\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f88669f-7054-41ad-8891-4e4850e557d0",
   "metadata": {},
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(\"[*] Tokenizer loaded.\")\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    token=access_token,\n",
    ").to(device)\n",
    "print(\"[*] Model loaded.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb8462da-334e-42c3-b012-65f29b074910",
   "metadata": {},
   "source": [
    "embedding_model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": device},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "vector_db_dir = os.path.join(base_dir, 'Vector_DB')\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(\n",
    "    vector_db_dir,\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a29708b5-6c6e-437a-8eab-67807901effd",
   "metadata": {},
   "source": [
    "formatted_df = pd.read_csv(os.path.join(base_dir, 'trainData/amazon_products.train.formatted.csv'))\n",
    "\n",
    "def retrieve_product_information(df, query_value):\n",
    "    product_index = df.index[df['PRODUCT_ID'] == query_value].tolist()[0]\n",
    "    full_text = formatted_df.loc[product_index, 'TEXT']\n",
    "    print(f'[*] Retrieved product full content:\\n{full_text}')\n",
    "\n",
    "    return formatted_df.loc[product_index, 'DESCRIPTION'], full_text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3835cc2e-cfa0-4039-b15b-6a247061e45b",
   "metadata": {},
   "source": [
    "Rec_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=1000,\n",
    "    device=device\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9494bf6a-84ab-4705-905b-609c128428a3",
   "metadata": {},
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in context, give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Information of recommended products must be correct and matched in context, do not falsify information.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\n",
    "\n",
    "Response must include product id, title, and reason for recommendation.\n",
    "Response must strictly follow the template below:\n",
    "i. - Product ID: <product id>: \n",
    "   - Title: <title>\n",
    "   - Reason: <reason for recommendation>\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7a4bacf-e443-4bb6-b8e9-1531edf2d026",
   "metadata": {},
   "source": [
    "random.seed(time())\n",
    "random_product_id = random.choice(formatted_df['PRODUCT_ID'])\n",
    "test_description, full_text = retrieve_product_information(formatted_df, random_product_id)\n",
    "\n",
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=test_description, k=11)[1:] # The first one will always be the qurey one, so skip it.\n",
    "retrieved_docs_text = [\n",
    "    doc.metadata['text'] for doc in retrieved_docs\n",
    "]  # We only need the text of the documents\n",
    "\n",
    "context = \"\\nExtracted products:\"\n",
    "context += \"\".join(\n",
    "    [f\"\\n\\nProduct {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
    ")\n",
    "\n",
    "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    question=\"Base on this product, recommend 5 best products from Context.\", context=context\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "41d6d3f6-c6a3-474a-bf26-aac0e177a116",
   "metadata": {},
   "source": [
    "# Redact an answer\n",
    "recommedations = Rec_LLM(final_prompt)[0][\"generated_text\"]\n",
    "print(recommedations)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "20f18ba5-893f-44fe-9a00-ced6ef9a467d",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Result Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adca9b7-efbe-450b-9d1d-7a525596c5f9",
   "metadata": {},
   "source": [
    "### Umap"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Access the FAISS index\n",
    "faiss_index = KNOWLEDGE_VECTOR_DATABASE.index\n",
    "\n",
    "# Access metadata\n",
    "metadata = KNOWLEDGE_VECTOR_DATABASE.docstore._dict  # Metadata is typically stored here"
   ],
   "id": "a150364c9273f7a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ],
   "id": "ba41973d28959f25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vectors = faiss_index.reconstruct_n(0, faiss_index.ntotal)",
   "id": "c81aaadf68937feb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reduce dimensions to 3D\n",
    "pca = PCA(n_components=3)\n",
    "reduced_vectors = pca.fit_transform(vectors)"
   ],
   "id": "efb85b32592a72e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot in 3D\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(\n",
    "    reduced_vectors[:, 0],\n",
    "    reduced_vectors[:, 1],\n",
    "    reduced_vectors[:, 2],\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "ax.set_title(\"3D Visualization of Products Vector Database\", fontsize=40)\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.tick_params(axis='z', labelsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fd3f8a1ce433cb6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### show with categories",
   "id": "4109660a2296467e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vector_categories = {}\n",
    "for i, v in tqdm(enumerate(metadata.values())):\n",
    "    curr_category = v.metadata['category']\n",
    "    vector_categories.setdefault(curr_category, [])\n",
    "    vector_categories[curr_category].append(reduced_vectors[i])"
   ],
   "id": "59d230c5f84cc40e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sort in descending by category length\n",
    "sorted_vector_categories = dict(sorted(vector_categories.items(), key=lambda item: len(item[1]), reverse=True))"
   ],
   "id": "84e237a121ee7d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for k, v in sorted_vector_categories.items():\n",
    "    print(k, len(v))"
   ],
   "id": "bf96e4772e532925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot in 3D\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for idx, (subset_name, subset_vectors) in enumerate(sorted_vector_categories.items()):\n",
    "    subset_vectors = np.array(subset_vectors)\n",
    "    ax.scatter(\n",
    "        subset_vectors[:, 0],\n",
    "        subset_vectors[:, 1],\n",
    "        subset_vectors[:, 2],\n",
    "        label=subset_name,  # Add label for the legend\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set_title(\"3D Visualization of Products Vector Database\", fontsize=40)\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.tick_params(axis='z', labelsize=15)\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bedae1168c6489c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "23494181d47b6ff8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
