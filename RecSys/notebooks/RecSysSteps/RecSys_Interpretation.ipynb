{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f12db5f-f8db-4779-a2bb-858fe22202e0",
   "metadata": {},
   "source": [
    "# LLM for Recommendation System - RAG\n",
    "\n",
    "## TABLE OF CONTENT\n",
    "### $~~~$ - 1. Recommendation System\n",
    "### $~~~$ - 2. Result Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838102f-2bd4-4f3f-bc10-2115dfbe6a30",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50b3d38-ee00-49e9-a6de-ee2a2f3a5ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Tue_Oct_29_23:50:19_PDT_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.85\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\n"
     ]
    }
   ],
   "source": [
    "# Check Python vision\n",
    "!python -V\n",
    "# Check CUDA vision\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3500fbf-bbbb-4e40-8f65-4727a0c49dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "from time import time \n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11be73e3-1784-4091-9074-d17e37915c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU Availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available else \"cpu\")\n",
    "#device = 'cpu' # Set to cpu when debugging\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "access_token = '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'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = access_token\n",
    "\n",
    "base_dir = \"../..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f88669f-7054-41ad-8891-4e4850e557d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Tokenizer loaded.\n",
      "[*] Model loaded.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(\"[*] Tokenizer loaded.\")\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    token=access_token,\n",
    ").to(device)\n",
    "print(\"[*] Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8462da-334e-42c3-b012-65f29b074910",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": device},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "vector_db_dir = os.path.join(base_dir, 'Vector_DB')\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(\n",
    "    vector_db_dir,\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29708b5-6c6e-437a-8eab-67807901effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df = pd.read_csv(os.path.join(base_dir, 'trainData/amazon_products.train.formatted.csv'))\n",
    "\n",
    "def retrieve_product_information(df, query_value):\n",
    "    product_index = df.index[df['PRODUCT_ID'] == query_value].tolist()[0]\n",
    "    full_text = formatted_df.loc[product_index, 'TEXT']\n",
    "    print(f'[*] Retrieved product full content:\\n{full_text}')\n",
    "\n",
    "    return formatted_df.loc[product_index, 'DESCRIPTION'], full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3835cc2e-cfa0-4039-b15b-6a247061e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=1000,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9494bf6a-84ab-4705-905b-609c128428a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 03 Jan 2025\n",
      "\n",
      "Using the information contained in context, give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Information of recommended products must be correct and matched in context, do not falsify information.\n",
      "If the answer cannot be deduced from the context, do not give an answer.\n",
      "\n",
      "Response must include product id, title, and reason for recommendation.\n",
      "Response must strictly follow the template below:\n",
      "i. - Product ID: <product id>: \n",
      "   - Title: <title>\n",
      "   - Reason: <reason for recommendation><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context:\n",
      "{context}\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: {question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in context, give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Information of recommended products must be correct and matched in context, do not falsify information.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\n",
    "\n",
    "Response must include product id, title, and reason for recommendation.\n",
    "Response must strictly follow the template below:\n",
    "i. - Product ID: <product id>: \n",
    "   - Title: <title>\n",
    "   - Reason: <reason for recommendation>\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a4bacf-e443-4bb6-b8e9-1531edf2d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Retrieved product full content:\n",
      "Product ID: B0BTVYS3MQ\n",
      "Title: Hilis Jewelry Evil Eye Necklace For Women Protection, Spiritual Jewelry, Personalized Gifts Glass Pendant Charm Engraved Gold or Silver D07\n",
      "Description: Personalized Engraved Women's Evil Eye Protection Spiritual Inspirational, Stainless Steel and Optional 18K Gold Plating Circle Glass Pendant Necklace in a Free Gift Box. This beautiful evil eye necklace is the perfect accessory for those looking to protect themselves from negative energy and bad luck. The necklace features a unique glass pendant with channeled art of evil eye protection, which is a symbol of protection and good luck in many cultures. The pendant is set in a high-quality polished stainless steel and finished with an adjustable chain. The evil eye is believed to ward off negative energy and protect the wearer from harm, making this necklace a powerful tool for personal empowerment and spiritual protection. The necklace is lightweight and comfortable to wear, making it a perfect everyday accessory. This necklace is a beautiful way to remind you to align your energy and focus on your spiritual protection and well-being. This necklace can be personalized with your choice of text, engraved on the back of the pendant.ITEM DETAILS:• One high-quality polished surgical steel pendant necklace.• Optional 18k gold plating.• Shatterproof liquid glass pendant.• Snake chain.• Measurements (approx.):• Circle pendant: 0.9” x 0.9” (23.5mm x 23.5mm).• Necklace Length: 18-22\" (45-56cm) adjustable. Optional back engraving:• Up to 2 lines.• Up to 20 characters per line (40 characters in total).\n",
      "Category: AMAZON FASHION\n",
      "Average rating: 4.5\n",
      "Price: 49.95\n",
      "Details: Department: Womens | Date First Available: February 4 | 2023\n"
     ]
    }
   ],
   "source": [
    "random.seed(time())\n",
    "random_product_id = random.choice(formatted_df['PRODUCT_ID'])\n",
    "test_description, full_text = retrieve_product_information(formatted_df, random_product_id)\n",
    "\n",
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=test_description, k=11)[1:] # The first one will always be the qurey one, so skip it.\n",
    "retrieved_docs_text = [\n",
    "    doc.metadata['text'] for doc in retrieved_docs\n",
    "]  # We only need the text of the documents\n",
    "\n",
    "context = \"\\nExtracted products:\"\n",
    "context += \"\".join(\n",
    "    [f\"\\n\\nProduct {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
    ")\n",
    "\n",
    "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    question=\"Base on this product, recommend 5 best products from Context.\", context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d6d3f6-c6a3-474a-bf26-aac0e177a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here are five recommendations for the best products from the list:\n",
      "\n",
      "1. **B0BWD3YZ1L** - Zaxsj Evil Eye Earrings Necklace for Women - 925 Sterling Silver Hypoallergenic Vintage Blue Evil Eye Earrings Pendant Necklace Protection Jewelry Birthday Christmas Gifts for Girls\n",
      "   Reason for Recommendation: This product stands out due to its hypoallergenic material, versatility, and affordability. It offers protection against negative energy and is suitable for daily wear.\n",
      "\n",
      "2. **B0BWW4MXJR** - Hilis Jewelry Evil Eye Necklace For Women Protection, Spiritual Jewelry, Personalized Glass Pendant Charm Engraved Gold or Silver D07\n",
      "   Reason for Recommendation: This product is notable for its unique design, high-quality materials, and customization options. It provides protection and spiritual benefits, making it a thoughtful gift for mothers.\n",
      "\n",
      "3. **B0BVD3YZ1L** - VIBILIA Evil Eye Necklace Sun Pendant Turkish Blue Eye Protection Lucky Necklaces Jewelry Gifts for Men Women (Sun) - Silver\n",
      "   Reason for Recommendation: Its stylish design, suitability for various occasions, and Turkish origin make it a popular choice. It offers protection and good luck, making it a practical gift option.\n",
      "\n",
      "4. **B0BTVYS3MQ** - TXIN 10 Pcs Glow in the Dark Crystal Pendant Necklace, Luminous Hexagonal Moonstone Necklace, Fluorescent Stone Necklace, Glowing Gemstone Quartz Stone Necklace with Black Leather Chain for Women Men\n",
      "   Reason for Recommendation: This product stands out due to its glowing effect, durability, and affordability. It's a versatile gift option that can be customized with different designs and colors.\n",
      "\n",
      "5. **B0BVT8M3VB** - VIBILIA Evil Eye Necklace Sun Pendant Turkish Blue Eye Protection Lucky Necklaces Jewelry Gifts for Men Women (Sun) - Silver\n",
      "   Reason for Recommendation: Similar to the previous product, this one offers protection and good luck through the evil eye symbolism. Its sleek design and silver finish make it a modern and stylish option.\n",
      "\n",
      "These recommendations cater to diverse preferences and needs based on the context provided.\n"
     ]
    }
   ],
   "source": [
    "# Redact an answer\n",
    "recommedations = Rec_LLM(final_prompt)[0][\"generated_text\"]\n",
    "print(recommedations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f18ba5-893f-44fe-9a00-ced6ef9a467d",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Result Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adca9b7-efbe-450b-9d1d-7a525596c5f9",
   "metadata": {},
   "source": [
    "### Umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93adbfd-438b-4843-b8c4-722e5a4dee44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
