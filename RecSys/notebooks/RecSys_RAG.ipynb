{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f12db5f-f8db-4779-a2bb-858fe22202e0",
   "metadata": {},
   "source": [
    "# LLM for Recommendation System - RAG\n",
    "\n",
    "## TABLE OF CONTENT\n",
    "### $~~~$ - 1. Load Data\n",
    "### $~~~$ - 2. Contruct Knowledge Base\n",
    "### $~~~$ - 3. Chunk Documents\n",
    "### $~~~$ - 4. Load Tokenizer and Model from HuggingFace\n",
    "### $~~~$ - 5. Embeddings and Retriever\n",
    "### $~~~$ - 6. Recommendation System\n",
    "### $~~~$ - 7. Apply xAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9b22ab-cadb-4fe4-b50b-a16e5859a9fa",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5358dd5-5703-46e1-9e16-52116addaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b4030-de35-45c0-bb8c-c10457461c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092d00d-8c96-45db-8250-3a02eead442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon products datasets\n",
    "products_path = os.path.join(base_dir, 'trainData/amazon_products.train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a394887-16b5-4ae1-bd06-f7a2bd1a8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "products_df = pd.read_csv(products_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4235e8e-25fb-4301-9e99-a7c9dac23680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the datasets\n",
    "print(\"[*] VTN Products Dataset:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883cdf3-51a0-4b0e-b9bc-513ad1408a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c2fff-9e7a-41f0-8ba0-caecdcf480b9",
   "metadata": {},
   "source": [
    "### (Optional) Drop rows without columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f99e6-fb92-4535-8df3-7cad11e42726",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.dropna(inplace=True)\n",
    "products_df.reset_index(inplace=True, drop=True)\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533e3c6-40eb-4dc1-b4a9-0f76c39b357c",
   "metadata": {},
   "source": [
    "### Construct Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74ae2d-1014-41a1-896e-50fc1ff4499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_text(row):\n",
    "    return (\n",
    "        f\"Product ID: {row['PRODUCT_ID']}\\n\"\n",
    "        f\"Title: {row['TITLE'].replace('\\n', ' ')}\\n\"\n",
    "        f\"Description: {row['DESCRIPTION'].replace('\\n', ' ')}\\n\"\n",
    "        f\"Category: {row['MAIN_CATEGORY']}\\n\"\n",
    "        f\"Average rating: {row['AVERAGE_RATING']}\\n\"\n",
    "        f\"Price: {row['PRICE']}\\n\"\n",
    "        f\"Details: {' | '.join((row['DETAILS'].strip('{}').replace('\\'', '').split(', ')))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa9285-6c07-449d-85f9-2695bfd33ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_texts = products_df.apply(construct_text, axis=1).tolist()\n",
    "print(f\"[*] Text format preview:\\n{product_texts[6]}\\n\\n{product_texts[7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60009cd9-63ca-4390-a0f6-1f1ed7ead728",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df = pd.DataFrame({\n",
    "    'PRODUCT_ID': products_df['PRODUCT_ID'].tolist(), \n",
    "    'TITLE': products_df['TITLE'].tolist(), \n",
    "    'DESCRIPTION': products_df['DESCRIPTION'].tolist(), \n",
    "    'CATEGORY': products_df['MAIN_CATEGORY'].tolist(), \n",
    "    'TEXT': product_texts\n",
    "})\n",
    "formatted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471baa33-0884-46a3-af65-2e2e5aaf2768",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Contruct Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a924e58-3bf9-493f-9386-8771b92d2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879947b8-2cdf-4693-be62-2513bffd38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=formatted_df.loc[i, \"DESCRIPTION\"], metadata={\n",
    "        \"id\": formatted_df.loc[i, \"PRODUCT_ID\"], \n",
    "        \"title\": formatted_df.loc[i, \"TITLE\"], \n",
    "        \"category\": formatted_df.loc[i, \"CATEGORY\"], \n",
    "        \"text\": formatted_df.loc[i, \"TEXT\"],\n",
    "    }) for i in tqdm(formatted_df.index)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15705db0-f3fc-494e-a278-b9a8baa44190",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_KNOWLEDGE_BASE[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56163d-84d3-418a-91c5-a3bde7e2f3dc",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Chunk Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915965f-1d3d-44cf-9d89-bf8070480df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41f6a3-b5b4-4d51-ad12-f1951c6cb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_SEP = [\n",
    "    \"\\n\",\n",
    "    \". \",\n",
    "    \".\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618da3c6-ca58-4163-b156-e1834b307019",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=100,\n",
    "    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
    "    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
    "    separators=customer_SEP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876780c1-595f-4456-91e0-3d127042f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_processed = []\n",
    "for doc in RAW_KNOWLEDGE_BASE:\n",
    "    docs_processed += text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d869071-e8a5-411e-8058-52d2b86dffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_processed[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838102f-2bd4-4f3f-bc10-2115dfbe6a30",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Tokenizer and Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b3d38-ee00-49e9-a6de-ee2a2f3a5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python vision\n",
    "!python -V\n",
    "# Check CUDA vision\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3500fbf-bbbb-4e40-8f65-4727a0c49dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from getpass import getpass\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be73e3-1784-4091-9074-d17e37915c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU Availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available else \"cpu\")\n",
    "#device = 'cpu' # Set to cpu when debugging\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be749e-38f5-4ca1-9340-0f446f1cd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ab499-62d8-4d15-a0a3-0bf452076a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = getpass()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec7b99-6c8f-4b33-bd19-ce40af255fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88669f-7054-41ad-8891-4e4850e557d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(\"[*] Tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d66327-4c4b-429f-8ce0-d8f362cf9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "# )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    token=access_token,\n",
    "    # quantization_config=bnb_config,\n",
    ").to(device)\n",
    "print(\"[*] Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed38f67-39d1-4601-98aa-8c203f32992b",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Embeddings and Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1477699-a74d-4430-975d-34dcbaa7ee46",
   "metadata": {},
   "source": [
    "### Check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836219ab-608f-4372-919b-46891e0bb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7ad02-18e6-4dc3-8038-d68f1937319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used in the RecursiveCharacterTextSplitter\n",
    "print(f\"[*] Model's maximum sequence length: {SentenceTransformer(model_id).max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3fa6d-bf85-4395-8211-eaedc804a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
    "print(f'[*] Max Token Length: {np.max(token_lengths)}')\n",
    "print(f'[*] Token Length <= 512: {round((len([x for x in token_lengths if x <= 512])/len(token_lengths))*100, 2)}%')\n",
    "print(f'[*] Token Length <= 1024: {round((len([x for x in token_lengths if x <= 1024])/len(token_lengths))*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb2b4e-0d32-4687-9beb-f64ca8e912f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(token_lengths, bins=20)\n",
    "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5a39a-58c9-482e-8e6e-ef7442f5507d",
   "metadata": {},
   "source": [
    "### Building the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae81ebc-02ee-4fc9-9bd1-1a06e7c04bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04e836-ee82-4b6d-b5b6-8552d8135ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a0706-00c1-474b-8f07-a8dec2df9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": device},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc83c80-a880-4e09-80a5-35567c9c09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd607f51d5ae05",
   "metadata": {},
   "source": [
    "### Save Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b03a2ff0b6c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_dir = os.path.join(base_dir, 'Vector_DB')\n",
    "KNOWLEDGE_VECTOR_DATABASE.save_local(vector_db_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7dc8920201b91",
   "metadata": {},
   "source": [
    "### Load Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef0c17fb39045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_dir = os.path.join(base_dir, 'Vector_DB')\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(\n",
    "    vector_db_dir,\n",
    "    embeddings=vector_db_dir,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77787861-884b-4a6c-90a7-4c76be896fd9",
   "metadata": {},
   "source": [
    "### Test Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e5662-6739-48b8-90c0-c40e831d1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29708b5-6c6e-437a-8eab-67807901effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_product_information(df, query_value):\n",
    "    product_index = df.index[df['PRODUCT_ID'] == query_value].tolist()[0]\n",
    "    full_text = formatted_df.loc[product_index, 'TEXT']\n",
    "    print(f'[*] Retrieved product full content:\\n{full_text}')\n",
    "\n",
    "    return formatted_df.loc[product_index, 'DESCRIPTION'], full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a0b0e-6f7d-4848-8a81-92a6259aaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(time())\n",
    "random_product_id = random.choice(formatted_df['PRODUCT_ID'])\n",
    "test_description, full_text = retrieve_product_information(formatted_df, random_product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a53d9-0aa9-4563-aae1-a335d7ec4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[*] Starting retrieval for description:\\n{test_description=}\\n\")\n",
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=test_description, k=6)[1:] # The first one will always be the qurey one, so skip it.\n",
    "print(\"==================================Top document==================================\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(\"====================================Full Content====================================\")\n",
    "print(retrieved_docs[0].metadata['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4350a-140a-4d77-956a-27b68efff9d3",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16057e17-138a-401c-b8d1-15bba0e6fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835cc2e-cfa0-4039-b15b-6a247061e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=1000,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2c883-f7ea-4248-9f09-5e62d1c30a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "Q = \"What is 4+4? Answer:\"\n",
    "A = Rec_LLM(Q)\n",
    "print(f'[*] {Q}{A[0]['generated_text']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2be54e-0e4e-4745-a946-e729fe26c0fd",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494bf6a-84ab-4705-905b-609c128428a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Response should include product id, title, and reason for recommendation.\n",
    "Information of recommended products must be correct, do not falsify information.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37ca2e-12eb-481d-ba42-ac2f96a0229a",
   "metadata": {},
   "source": [
    "### Recommendation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4bacf-e443-4bb6-b8e9-1531edf2d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(time())\n",
    "random_product_id = random.choice(formatted_df['PRODUCT_ID'])\n",
    "test_description, full_text = retrieve_product_information(formatted_df, random_product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acfa4b-18de-406f-8515-b3f5a12fb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=test_description, k=11)[1:] # The first one will always be the qurey one, so skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6d3f6-c6a3-474a-bf26-aac0e177a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs_text = [\n",
    "    doc.metadata['text'] for doc in retrieved_docs\n",
    "]  # We only need the text of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fad6d-074a-423f-8005-fa2cd58d0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\nExtracted products:\"\n",
    "context += \"\".join(\n",
    "    [f\"\\n\\nProduct {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f5d69-2ba8-4ffc-b764-6c0d9c7f0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    question=\"Base on this product, recommend 5 best products from Context.\", context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92cda77-af1e-47a5-b3a4-6c7b5b44890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redact an answer\n",
    "recommedations = Rec_LLM(final_prompt)[0][\"generated_text\"]\n",
    "print(recommedations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db36b13-d716-4c9d-a480-c6ae75b62f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e86f5-be64-4d27-8145-81994c4fe737",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Apply xAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b8520-15c1-47aa-be9a-7467c9240d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    FeatureAblation, \n",
    "    ShapleyValueSampling,\n",
    "    LayerIntegratedGradients, \n",
    "    LLMAttribution, \n",
    "    LLMGradientAttribution, \n",
    "    TextTokenInput, \n",
    "    TextTemplateInput,\n",
    "    ProductBaselines,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918ef50-0816-42a8-84b5-dcf4318548f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = recommedations.split('\\n\\n')[1:]\n",
    "# targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9bb5e-4fcd-4e29-ba8c-3a1452779754",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompts = retrieved_docs_text\n",
    "# eval_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd74ab1-ab43-4917-a41d-e740967ee86d",
   "metadata": {},
   "source": [
    "### Perturbation-based Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f7994-1973-4158-9527-d45075d7b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PBA_eval(tokenizer, eval_prompt, target):\n",
    "    skip_tokens = [1]  # skip the special token for the start of the text <s>\n",
    "    inp = TextTokenInput(\n",
    "        eval_prompt, \n",
    "        tokenizer,\n",
    "        skip_tokens=skip_tokens,\n",
    "    )\n",
    "\n",
    "    fa = FeatureAblation(model)\n",
    "    llm_attr = LLMAttribution(fa, tokenizer)\n",
    "\n",
    "    print('[*] Calculating attribution...')\n",
    "    attr_res = llm_attr.attribute(\n",
    "        inp, \n",
    "        target=target, \n",
    "        skip_tokens=skip_tokens,\n",
    "    )\n",
    "\n",
    "    print(\"[*] Attribution to the output sequence:\", attr_res.seq_attr.shape)  # shape(n_input_token)\n",
    "    print(\"[*] Attribution to the output tokens:\", attr_res.token_attr.shape)  # shape(n_output_token, n_input_token)\n",
    "\n",
    "    attr_res.plot_token_attr(show=True)\n",
    "\n",
    "    return attr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dabb9-24a2-489b-9e0e-8cdbca273091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attr_res = PBA_eval(tokenizer, eval_prompts[0], targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7764b4f",
   "metadata": {},
   "source": [
    "### Shapley Value Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56f0ae-ed0e-4d12-bc67-807d5b4fe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SV_PBA_eval(tokenizer, eval_prompt, target):\n",
    "    skip_tokens = [1]  # skip the special token for the start of the text <s>\n",
    "    inp = TextTokenInput(\n",
    "        eval_prompt, \n",
    "        tokenizer,\n",
    "        skip_tokens=skip_tokens,\n",
    "    )\n",
    "\n",
    "    sv = ShapleyValueSampling(model)\n",
    "    sv_llm_attr = LLMAttribution(sv, tokenizer)\n",
    "\n",
    "    print('[*] Calculating attribution...')\n",
    "    attr_res = sv_llm_attr.attribute(\n",
    "        inp, \n",
    "        target=target, \n",
    "        # skip_tokens=skip_tokens, \n",
    "        num_trials=3\n",
    "    )\n",
    "\n",
    "    print(\"[*] Attribution to the output sequence:\", attr_res.seq_attr.shape)  # shape(n_input_token)\n",
    "    print(\"[*] Attribution to the output tokens:\", attr_res.token_attr.shape)  # shape(n_output_token, n_input_token)\n",
    "\n",
    "    attr_res.plot_token_attr(show=True)\n",
    "\n",
    "    return attr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91bfa9-9a4f-435c-8488-7852aa15895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_attr_res = SV_PBA_eval(tokenizer, eval_prompts[0], targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefc9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
