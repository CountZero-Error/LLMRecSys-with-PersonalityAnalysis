{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220973365a6f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from getpass import getpass\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys:\n",
    "    def __init__(self, model:str, vector_db:str, access_token:str, product_description:str, k:int = 15, use_4bit:bool = False):\n",
    "        self.model = model\n",
    "        self.vector_db = vector_db\n",
    "        self.product_description = product_description\n",
    "        self.k = k\n",
    "        self.use_4bit = use_4bit\n",
    "        self.device = ''\n",
    "        self.access_token = access_token\n",
    "        self.prompt_in_chat_format = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Using the information contained in context, give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Information of recommended products must be correct and matched in context, do not falsify information.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\n",
    "\n",
    "Response must include product id, title, and reason for recommendation.\n",
    "Response must strictly follow the template below:\n",
    "i. **Product ID: <Product ID>** - <Title>\n",
    "Reason: <Reason>\n",
    "\n",
    "Answer examples:\n",
    "1. **Product ID: B0C3WNM5X7** - Simple Joys by Carter's Toddler Boys' Hooded Sweater Jacket with Sherpa Lining\n",
    "Reason: This product is highly rated with an average rating of 4.8, offering excellent value for its price.\n",
    "\n",
    "2. **Product ID: B0C1X12894** - Oversized Wearable Blanket Hoodie for Women Men Comfy Sweatshirt\n",
    "Reason: This product is highly rated with an average rating of 4.8, making it a great option for those looking for a cozy and warm garment.\n",
    "\n",
    "3. **Product ID: B0C68CBFKS** - Columbia Women's West Bend Hoodie\n",
    "Reason: This product is highly rated with an average rating of 4.4, offering a reliable and affordable option for casual wear.\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"Context:\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    def initialize(self):\n",
    "        # Set hardware\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"[*] Using device: {self.device}\")\n",
    "\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "        match self.model:\n",
    "            case \"Llama3.2\":\n",
    "                model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "            case \"Qwen2.5\":\n",
    "                model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "        '''Tokenizer and Model'''\n",
    "        # Load Tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id, token=self.access_token)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.padding_side = \"right\"\n",
    "        print(\"[*] Tokenizer loaded.\")\n",
    "\n",
    "        # Load Model\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "\n",
    "        if self.use_4bit:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_id,\n",
    "                token=self.access_token,\n",
    "                quantization_config=bnb_config,\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_id,\n",
    "                token=self.access_token,\n",
    "            ).to(self.device)\n",
    "\n",
    "        print(\"[*] Model loaded.\")\n",
    "\n",
    "        return tokenizer, model\n",
    "\n",
    "    def load_vector_db(self):\n",
    "        embedding_model = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            multi_process=True,\n",
    "            model_kwargs={\"device\": \"cuda\"},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    "        )\n",
    "\n",
    "        loaded_vector_database = FAISS.load_local(\n",
    "            self.vector_db,\n",
    "            embeddings=embedding_model,\n",
    "            allow_dangerous_deserialization=True,\n",
    "        )\n",
    "\n",
    "        print('[*] Vector database loaded.')\n",
    "\n",
    "        return loaded_vector_database\n",
    "\n",
    "    def recommend(self):\n",
    "        print(\"[*] Initrializing...\")\n",
    "        tokenizer, model = self.initialize()\n",
    "        KNOWLEDGE_VECTOR_DATABASE = self.load_vector_db()\n",
    "        print('[*] Done.')\n",
    "\n",
    "        '''Prompt Template'''\n",
    "        RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "            self.prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        '''Retrieve Similar Products from Vector Database'''\n",
    "        print(f'[*] Retrieving {self.k} similar products...')\n",
    "        retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=self.product_description, k=self.k+1)[1:]  # The first one will always be the qurey one, so skip it.\n",
    "        retrieved_docs_text = [doc.metadata['text'] for doc in retrieved_docs]\n",
    "        print('[*] Done.')\n",
    "\n",
    "        '''Format Prompt'''\n",
    "        print('[*] Formatting prompt...')\n",
    "        context = \"\\nExtracted products:\"\n",
    "        context += \"\".join(\n",
    "            [f\"\\n\\nProduct {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
    "        )\n",
    "\n",
    "        final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "            question=\"Base on this product, recommend 5 best products from Context. And for each recommended product, give a reason.\", context=context\n",
    "        )\n",
    "\n",
    "        # print(f'\\n[!] Prompt: \\n{final_prompt}\\n')\n",
    "\n",
    "        print('[*] Done.')\n",
    "\n",
    "        '''Generate Recommendations'''\n",
    "        Rec_LLM = pipeline(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            task=\"text-generation\",\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            repetition_penalty=1.1,\n",
    "            return_full_text=False,\n",
    "            max_new_tokens=1000,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        print('[*] Generating Recommendations...')\n",
    "        recommendations = Rec_LLM(final_prompt)[0][\"generated_text\"]\n",
    "        print('[*] Done.')\n",
    "\n",
    "        return recommendations, retrieved_docs_text, KNOWLEDGE_VECTOR_DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e942d69962c1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecInterpreter:\n",
    "    def __init__(self, KNOWLEDGE_VECTOR_DATABASE, recommendations:str, target_id:str, candidates:list):\n",
    "        self.faiss_idx = KNOWLEDGE_VECTOR_DATABASE.index\n",
    "        self.metadata = KNOWLEDGE_VECTOR_DATABASE.docstore._dict\n",
    "        self.vectors = self.faiss_idx.reconstruct_n(0, self.faiss_idx.ntotal)\n",
    "        self.recommendations = recommendations\n",
    "        self.target_id = target_id\n",
    "        self.candidates = candidates\n",
    "\n",
    "    def preprocess(self):\n",
    "        '''vector database'''\n",
    "        pca = PCA(n_components=3)\n",
    "        reduced_vectors = pca.fit_transform(self.vectors)\n",
    "\n",
    "        vector_categories = {}\n",
    "        for i, v in enumerate(self.metadata.values()):\n",
    "            curr_category = v.metadata['category']\n",
    "            vector_categories.setdefault(curr_category, [])\n",
    "            vector_categories[curr_category].append(reduced_vectors[i])\n",
    "\n",
    "        # sort in descending by category length\n",
    "        sorted_vector_categories = dict(sorted(vector_categories.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "        '''recommendations'''\n",
    "        recommendation_pattern = re.compile(r\"\\*\\*Product ID: (.*)\\*\\*\")\n",
    "        recommendation_ids = [x.split()[-1] for x in recommendation_pattern.findall(self.recommendations)]\n",
    "\n",
    "        # Check IDs\n",
    "        # print(f'[!] recommended IDs: {ids}')\n",
    "\n",
    "        '''candidates'''\n",
    "        candidate_pattern = r\"Product ID:\\s*(\\w+)\"\n",
    "        _candidate_ids = []\n",
    "        for candidate in self.candidates:\n",
    "            _candidate_ids += re.findall(candidate_pattern, candidate)\n",
    "\n",
    "        # Intersect with recommendations\n",
    "        candidate_ids = []\n",
    "        for candidate_id in _candidate_ids:\n",
    "            if candidate_id not in recommendation_ids:\n",
    "                candidate_ids.append(candidate_id)\n",
    "\n",
    "        # Check IDs\n",
    "        # print(f'[!] candidate IDs: {candidate_ids}')\n",
    "\n",
    "        '''get vector'''\n",
    "        recommendation_vectors = {}\n",
    "        matched_products = {}\n",
    "        target_retrieved, recommendations_retrieved, candidates_retrieved = 0, 0, 0\n",
    "        for i, v in enumerate(self.metadata.values()):\n",
    "            curr_id = v.metadata['id']\n",
    "            if curr_id == self.target_id and target_retrieved == 0:\n",
    "                recommendation_vectors.setdefault('Target Product', [])\n",
    "                recommendation_vectors['Target Product'].append(reduced_vectors[i])\n",
    "                target_retrieved += 1\n",
    "\n",
    "                matched_products.setdefault('Target Product', [])\n",
    "                matched_products['Target Product'].append(curr_id)\n",
    "                \n",
    "            elif curr_id in recommendation_ids and recommendations_retrieved < 5:\n",
    "                recommendation_vectors.setdefault('Recommended Product', [])\n",
    "                recommendation_vectors['Recommended Product'].append(reduced_vectors[i])\n",
    "                recommendations_retrieved += 1\n",
    "\n",
    "                matched_products.setdefault('Recommended Product', [])\n",
    "                matched_products['Recommended Product'].append(curr_id)\n",
    "\n",
    "            elif curr_id in candidate_ids and candidates_retrieved < 10:\n",
    "                recommendation_vectors.setdefault('Candidate Product', [])\n",
    "                recommendation_vectors['Candidate Product'].append(reduced_vectors[i])\n",
    "                candidates_retrieved += 1\n",
    "\n",
    "                matched_products.setdefault('Candidate Product', [])\n",
    "                matched_products['Candidate Product'].append(curr_id)\n",
    "\n",
    "        # Check\n",
    "        for k, v in recommendation_vectors.items():\n",
    "            print(f'[!] {k}({len(v)}): {matched_products[k]}')\n",
    "\n",
    "        return sorted_vector_categories, recommendation_vectors\n",
    "\n",
    "    def vis_3d(self, save2local:str=''):\n",
    "        sorted_vector_categories, recommendation_vectors = self.preprocess()\n",
    "\n",
    "        # Plot in 3D\n",
    "        fig = plt.figure(figsize=(40, 20))\n",
    "\n",
    "        '''Vector Database'''\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "        for idx, (subset_name, subset_vectors) in enumerate(sorted_vector_categories.items()):\n",
    "            subset_vectors = np.array(subset_vectors)\n",
    "\n",
    "            # Reduce background size\n",
    "            # subset_vectors_len = len(subset_vectors)\n",
    "            # if subset_vectors_len >= 1000:\n",
    "            #     subset_vectors = subset_vectors[:1000]\n",
    "            # else:\n",
    "            #     subset_vectors = subset_vectors[:int(round(subset_vectors_len/2,0))]\n",
    "\n",
    "            ax1.scatter(\n",
    "                subset_vectors[:, 0],\n",
    "                subset_vectors[:, 1],\n",
    "                subset_vectors[:, 2],\n",
    "                label=subset_name.lower().title(),  # Add label for the legend\n",
    "                alpha=0.3,\n",
    "            )\n",
    "\n",
    "        ax1.set_title(\"3D Visualization of Products Vector Database (Whole)\", fontsize=40)\n",
    "        ax1.tick_params(axis='x', labelsize=15)\n",
    "        ax1.tick_params(axis='y', labelsize=15)\n",
    "        ax1.tick_params(axis='z', labelsize=15)\n",
    "        ax1.legend(fontsize=15)\n",
    "\n",
    "        '''Target & Recommendation'''\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "        # Vector Database\n",
    "        for idx, (subset_name, subset_vectors) in enumerate(sorted_vector_categories.items()):\n",
    "            subset_vectors = np.array(subset_vectors)\n",
    "\n",
    "            # Reduce background size\n",
    "            subset_vectors_len = len(subset_vectors)\n",
    "            if subset_vectors_len >= 1000:\n",
    "                subset_vectors = subset_vectors[:500]\n",
    "            else:\n",
    "                subset_vectors = subset_vectors[:int(round(subset_vectors_len / 2, 0))]\n",
    "\n",
    "            ax2.scatter(\n",
    "                subset_vectors[:, 0],\n",
    "                subset_vectors[:, 1],\n",
    "                subset_vectors[:, 2],\n",
    "                label=subset_name.lower().title(),  # Add label for the legend\n",
    "                alpha=0.3,\n",
    "            )\n",
    "\n",
    "        # Target Product & Recommeded Products\n",
    "        for idx, (subset_name, subset_vectors) in enumerate(recommendation_vectors.items()):\n",
    "            subset_vectors = np.array(subset_vectors)\n",
    "\n",
    "            marker = 'x'\n",
    "            if subset_name == 'Target Product':\n",
    "                marker = 'o'\n",
    "            elif subset_name == 'Candidate Product':\n",
    "                marker = '+'\n",
    "\n",
    "            ax2.scatter(\n",
    "                subset_vectors[:, 0],\n",
    "                subset_vectors[:, 1],\n",
    "                subset_vectors[:, 2],\n",
    "                label=subset_name,  # Add label for the legend\n",
    "                alpha=1,\n",
    "                marker=marker,\n",
    "                color='black',\n",
    "                linewidths=3,\n",
    "                s=300,\n",
    "            )\n",
    "\n",
    "        ax2.set_title(\"3D Visualization of Target Product & Recommended Products\", fontsize=40)\n",
    "        ax2.tick_params(axis='x', labelsize=15)\n",
    "        ax2.tick_params(axis='y', labelsize=15)\n",
    "        ax2.tick_params(axis='z', labelsize=15)\n",
    "        ax2.legend(fontsize=15)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save2local != '':\n",
    "            plt.savefig(save2local)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    def recommendations_info(self):\n",
    "        recommendation_pattern = re.compile(r\"\\*\\*Product ID: (.*)\\*\\*\")\n",
    "        recommendation_ids = [x.split()[-1] for x in recommendation_pattern.findall(self.recommendations)]\n",
    "\n",
    "        recs_info = {}\n",
    "        for v in self.metadata.values():\n",
    "            curr_id = v.metadata['id']\n",
    "            if curr_id in recommendation_ids:\n",
    "                recs_info.setdefault(curr_id, '')\n",
    "                recs_info[curr_id] = v.metadata['text']\n",
    "\n",
    "        print(f'\\n[*] Recommended Products Information:')\n",
    "        for v in recs_info.values():\n",
    "            print(f'{v}\\n')\n",
    "\n",
    "    def candidates_info(self):\n",
    "        print(f'\\n[*] Candidate Products Information:')\n",
    "        for candidate in self.candidates:\n",
    "            print(f'{candidate}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62843e3b4f676fd6",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35da967bace134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_product_information(df, query_value):\n",
    "    product_index = df.index[df['PRODUCT_ID'] == query_value].tolist()[0]\n",
    "    full_text = df.loc[product_index, 'TEXT']\n",
    "    product_id = df.loc[product_index, 'PRODUCT_ID']\n",
    "    print(f'[*] Retrieved product full content:\\n{full_text}')\n",
    "\n",
    "    return df.loc[product_index, 'DESCRIPTION'], full_text, product_id\n",
    "\n",
    "random.seed(time())\n",
    "formatted_df = pd.read_csv('trainData/amazon_products.train.formatted.csv')\n",
    "random_product_id = random.choice(formatted_df['PRODUCT_ID'])\n",
    "\n",
    "test_description, full_text, target_id = retrieve_product_information(formatted_df, random_product_id)\n",
    "\n",
    "'''RecSys'''\n",
    "recSys = RecSys(\n",
    "    # model='Llama3.2',\n",
    "    model='Qwen2.5',\n",
    "    vector_db='./Vector_DB',\n",
    "    access_token='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',\n",
    "    product_description=test_description,\n",
    "    k=15,\n",
    ")\n",
    "\n",
    "recommendations, retrieved_docs_text, KNOWLEDGE_VECTOR_DATABASE = recSys.recommend()\n",
    "\n",
    "print(f'Recommendations:\\n{recommendations}\\n\\n')\n",
    "\n",
    "'''Interpreter'''\n",
    "recInterpreter = RecInterpreter(\n",
    "    KNOWLEDGE_VECTOR_DATABASE=KNOWLEDGE_VECTOR_DATABASE,\n",
    "    recommendations=recommendations,\n",
    "    target_id=target_id,\n",
    "    candidates=retrieved_docs_text,\n",
    ")\n",
    "\n",
    "recInterpreter.vis_3d('vectors.png')\n",
    "recInterpreter.recommendations_info()\n",
    "recInterpreter.candidates_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
