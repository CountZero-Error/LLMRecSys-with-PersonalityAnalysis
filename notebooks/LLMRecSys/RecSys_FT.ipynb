{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e30c44-0f87-47b8-976f-67b9be87d91c",
   "metadata": {},
   "source": [
    "# LLM for Recommendation System - Fine-Tuned\n",
    "\n",
    "## TABLE OF CONTENT\n",
    "### $~~~$ - 1. Load Data\n",
    "### $~~~$ - 2. Load model from Local\n",
    "### $~~~$ - 3. Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c5f23-4c78-426a-85e3-3b3b69fe6648",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ad120-43c5-4975-96f4-2b3282c4ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee416dba-36aa-46a5-ae6a-b901235aa843",
   "metadata": {},
   "outputs": [],
   "source": "base_dir = \"../../\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0779c-b2e3-41de-aba5-3cc172803fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon products datasets\n",
    "products_path = os.path.join(base_dir, 'trainData/amazon_products.train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94021af4-baca-49bd-bd4b-076a813ce406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "products_df = pd.read_csv(products_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076dabc-6c4b-45a3-8457-f951e75b1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the datasets\n",
    "print(\"[*] VTN Products Dataset:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317bdc6-2474-46c4-80f1-1a5bbf413921",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77e660-4780-49c2-b137-5731b907fa56",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load model from Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46b012-dda3-4f1f-87e9-20d122ea6c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python vision\n",
    "!python -V\n",
    "# Check CUDA vision\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8611683-f291-46b5-a70a-fc240073adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4e539-3f73-4892-ae80-6827571786d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU Availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available else \"cpu\")\n",
    "#device = 'cpu' # Set to cpu when debugging\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e17075-7669-4a15-b32e-e8247b14eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7279e3-262c-422d-84c3-dfd0894a9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = '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'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabe7cf-a84b-47b1-9e4b-1115d15a8aae",
   "metadata": {},
   "source": [
    "### Llama 3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c58662-dc48-415c-b812-36941d03c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23de16-b420-46a6-b0d3-84c8e000d3b7",
   "metadata": {},
   "source": [
    "### Qwen 2.5-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f47ad-3b05-49c5-af7e-d6b7af8f82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"Qwen/Qwen2.5-1.5B\"\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3ddd3-6402-4284-abdc-a505a10cfff7",
   "metadata": {},
   "source": [
    "### Load from Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30faa610-4f74-47c5-9f02-ec797aaa017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = os.path.join(base_dir, f\"models/{model_id.split('/')[-1]}/Final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a713c6-d7b7-4481-82a8-88f2cf0dde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, token=access_token)\n",
    "print(\"[*] Tokenizer loaded.\")\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, token=access_token).to(device)\n",
    "print(\"[*] Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f182b80-5f1a-4a81-a2fd-e00b3a26e850",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75677dd8-6f70-4cb9-b75a-949201b6f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pad_token_id\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c8024-7c1e-4ac4-9aae-aaddcfef124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Name: {products_df.loc[0, 'TITLE']}\\nBULLET_POINTS:\\n\\t{products_df.loc[0, 'BULLET_POINTS']}\\nDESCRIPTION:\\n\\t{products_df.loc[0, 'DESCRIPTION']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec35478-1d8e-496b-a7e6-367796a41961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# from captum.attr import (\n",
    "#     FeatureAblation, \n",
    "#     ShapleyValues,\n",
    "#     LayerIntegratedGradients, \n",
    "#     LLMAttribution, \n",
    "#     LLMGradientAttribution, \n",
    "#     TextTokenInput, \n",
    "#     TextTemplateInput,\n",
    "#     ProductBaselines,\n",
    "# )\n",
    "\n",
    "# # Ignore warnings due to transformers library\n",
    "# warnings.filterwarnings(\"ignore\", \".*past_key_values.*\")\n",
    "# warnings.filterwarnings(\"ignore\", \".*Skipping this token.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fae0e-e7e4-48b6-b4c3-ca475a72aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = 'Introduce me product: PRIKNIK Horn Red Electric Air Horn Compressor Interior Dual Tone Trumpet Loud Compatible with SX4.\\nAnswer here:\\n\\t'\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(model_input[\"input_ids\"], max_new_tokens=500)[0]\n",
    "    response = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37608c8c-0c36-4ef7-8e1e-075d16c8b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fa = FeatureAblation(model)\n",
    "\n",
    "# llm_attr = LLMAttribution(fa, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a153e6-512b-4484-8de5-97b29bd4aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_tokens = [1]  # skip the special token for the start of the text <s>\n",
    "# inp = TextTokenInput(\n",
    "#     eval_prompt, \n",
    "#     tokenizer,\n",
    "#     skip_tokens=skip_tokens,\n",
    "# )\n",
    "\n",
    "# attr_res = llm_attr.attribute(inp, target=eval_prompt, skip_tokens=skip_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1aa7f-c791-4197-a2df-e3d0c74bbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"attr to the output sequence:\", attr_res.seq_attr.shape)  # shape(n_input_token)\n",
    "# print(\"attr to the output tokens:\", attr_res.token_attr.shape)  # shape(n_output_token, n_input_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15626ecb-d796-4c56-93d9-593a0aacbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr_res.plot_token_attr(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7689155-b33f-40c7-94f2-90333cc37199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
